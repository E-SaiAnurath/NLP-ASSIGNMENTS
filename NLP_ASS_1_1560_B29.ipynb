{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0hmqm9z3hmg25xjlXthBE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/E-SaiAnurath/NLP-ASSIGNMENTS/blob/main/NLP_ASS_1_1560_B29.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ASSIGNMENT-1 (1560) (B29)"
      ],
      "metadata": {
        "id": "P_6xcSn3pROy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section A: Load & Explore\n",
        "Q1. Load sample resumes and display first 3 rows. Check for noisy characters like \\n, •, and symbols"
      ],
      "metadata": {
        "id": "08qj5EenpMhX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UxrMx0zMXdR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('bbc_news.csv')"
      ],
      "metadata": {
        "id": "A954cjFDMdr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First 3 rows:\")\n",
        "print(df.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ORzlSrQOwok",
        "outputId": "6df5c1d6-4f1c-4dd0-bf95-2d72d03e3824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 3 rows:\n",
            "                                               title  \\\n",
            "0  Ukraine: Angry Zelensky vows to punish Russian...   \n",
            "1  War in Ukraine: Taking cover in a town under a...   \n",
            "2         Ukraine war 'catastrophic for global food'   \n",
            "\n",
            "                         pubDate  \\\n",
            "0  Mon, 07 Mar 2022 08:01:56 GMT   \n",
            "1  Sun, 06 Mar 2022 22:49:58 GMT   \n",
            "2  Mon, 07 Mar 2022 00:14:42 GMT   \n",
            "\n",
            "                                               guid  \\\n",
            "0  https://www.bbc.co.uk/news/world-europe-60638042   \n",
            "1  https://www.bbc.co.uk/news/world-europe-60641873   \n",
            "2      https://www.bbc.co.uk/news/business-60623941   \n",
            "\n",
            "                                                link  \\\n",
            "0  https://www.bbc.co.uk/news/world-europe-606380...   \n",
            "1  https://www.bbc.co.uk/news/world-europe-606418...   \n",
            "2  https://www.bbc.co.uk/news/business-60623941?a...   \n",
            "\n",
            "                                         description  \n",
            "0  The Ukrainian president says the country will ...  \n",
            "1  Jeremy Bowen was on the frontline in Irpin, as...  \n",
            "2  One of the world's biggest fertiliser firms sa...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nChecking for noisy characters in 'description' column:\")\n",
        "for i in range(3):\n",
        "    print(f\"\\nDescription {i+1}:\")\n",
        "    print(df['description'].iloc[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxFPNAH-PF9a",
        "outputId": "2341da5e-c1a7-4c53-9aa1-6d8d92a83a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checking for noisy characters in 'description' column:\n",
            "\n",
            "Description 1:\n",
            "The Ukrainian president says the country will not forgive or forget those who murder its civilians.\n",
            "\n",
            "Description 2:\n",
            "Jeremy Bowen was on the frontline in Irpin, as residents came under Russian fire while trying to flee.\n",
            "\n",
            "Description 3:\n",
            "One of the world's biggest fertiliser firms says the conflict could deliver a shock to food supplies.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section B: NLTK Preprocessing\n",
        "Q2. Use NLTK to:\n",
        "\n",
        "·       Clean special characters and digits\n",
        "\n",
        "·       Tokenize and stem\n",
        "\n",
        "·       Remove stop words\n",
        "\n",
        "·       Extract top 10 frequent stemmed words"
      ],
      "metadata": {
        "id": "rnLlipO5b3ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "bwBiXcb6Pzm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')         # Tokenizer models (includes punkt_tab)\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YRc6-9LSzAj",
        "outputId": "e0ed0ffd-5bf8-4c7f-ac9e-a3242c7d563e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = df['description'].dropna().astype(str)\n",
        "cleaned_texts = text_data.apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x.lower()))\n"
      ],
      "metadata": {
        "id": "DzXApLRoQDxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "tokens = [nltk.word_tokenize(text) for text in cleaned_texts]\n",
        "stemmed_tokens = [[stemmer.stem(word) for word in words] for words in tokens]"
      ],
      "metadata": {
        "id": "cd7NqI2cQRJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [[word for word in words if word not in stop_words] for words in stemmed_tokens]"
      ],
      "metadata": {
        "id": "CbqFAUtebWKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_tokens = [word for sublist in filtered_tokens for word in sublist]\n",
        "top_10_stemmed = Counter(flat_tokens).most_common(10)"
      ],
      "metadata": {
        "id": "M302wf_abdAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n🔟 Top 10 Frequent Stemmed Words (NLTK):\")\n",
        "for word, freq in top_10_stemmed:\n",
        "    print(f\"{word}: {freq}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n15RV8Fibgxa",
        "outputId": "9068a255-06ba-4f18-e5fe-4ee970f367f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔟 Top 10 Frequent Stemmed Words (NLTK):\n",
            "say: 6397\n",
            "hi: 4120\n",
            "wa: 3868\n",
            "ha: 3846\n",
            "bbc: 2408\n",
            "england: 2338\n",
            "year: 2251\n",
            "world: 2170\n",
            "peopl: 2021\n",
            "first: 1909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section C: spaCy Pipeline\n",
        "Q3. Use spaCy to:\n",
        "\n",
        "·       Tokenize and lemmatize\n",
        "\n",
        "·       Filter tokens: only include alphabetic nouns and verbs\n",
        "\n",
        "·       Extract top 10 frequent lemmas"
      ],
      "metadata": {
        "id": "PnJRR3swnweV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "68IVUQdin3sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn6H-fGBoGAd",
        "outputId": "5756b942-15d1-4f57-daa8-a0645f702029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmas = []\n",
        "for doc in nlp.pipe(text_data, disable=[\"ner\", \"parser\"]):\n",
        "    for token in doc:\n",
        "        if token.is_alpha and token.pos_ in ['NOUN', 'VERB']:\n",
        "            lemmas.append(token.lemma_.lower())"
      ],
      "metadata": {
        "id": "iJl7BeMaoNRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_10_lemmas = Counter(lemmas).most_common(10)\n",
        "\n",
        "print(\"\\n🔟 Top 10 Frequent Lemmas (spaCy):\")\n",
        "for lemma, freq in top_10_lemmas:\n",
        "    print(f\"{lemma}: {freq}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTZ61r5foTIP",
        "outputId": "cf69583c-36b1-43ec-edc4-429f67916a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔟 Top 10 Frequent Lemmas (spaCy):\n",
            "say: 7139\n",
            "year: 2994\n",
            "people: 2018\n",
            "win: 1986\n",
            "take: 1646\n",
            "day: 1505\n",
            "make: 1475\n",
            "time: 1210\n",
            "find: 1148\n",
            "show: 1118\n"
          ]
        }
      ]
    }
  ]
}